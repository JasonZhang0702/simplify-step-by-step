from transformers import AutoModelForCausalLM, AutoTokenizer
import pandas as pd
from tqdm import tqdm
import sys
from vllm import LLM, SamplingParams
import os
from utils import CEFR_Descriptors
import copy
import json
import argparse
CEFRMAP = {
    1: "A1", 2: "A2", 3: "B1", 4: "B2", 5: "C1", 6: "C2"
}


def clean_llm_generation(generation):
    sentlist = generation.split("\n")
    for sent in sentlist:
        sent = sent.strip()
        if sent != "":
            return sent
    return None


def padding_case(case_dict_expert):
    for begin_cefr in [6, 5, 4, 3, 2]:
        for target_cefr in range(begin_cefr-1, 0, -1):
            if f"{begin_cefr}{target_cefr}" not in case_dict_expert:
                case_dict_expert[f"{begin_cefr}{target_cefr}"] = []
    return case_dict_expert


def get_prompt(prompt_case_pair, prompt_case_single, complex_sentence, CEFR_LEVEL, CEFR_Description):
    CEFR_LEVEL = CEFRMAP[CEFR_LEVEL]
    content = f"Please rewrite the following complex sentence in order to make it easier to understand by {CEFR_LEVEL} CEFR level language learners. " \
                f"{CEFR_LEVEL} level language learner {CEFR_Description}" \
                "You can do so by replacing " \
                "complex words with simpler synonyms (i.e. paraphrasing), deleting unimportant information (i.e. compression), and/or splitting a long " \
                "complex sentence into several simpler ones. The final simplified sentence needs to be grammatical, fluent, and retain the main ideas " \
                f"of its original counterpart without altering its meaning."
    if len(prompt_case_pair) > 0:
        content += f"The following are examples of simplification for {CEFR_LEVEL} CEFR level language learners:\n"
        for i in range(len(prompt_case_pair)):
            content += f"Complex:{prompt_case_pair[i][0]}\nSimple:{prompt_case_pair[i][1]}\n\n"
    else:
        content += f"The following are examples of sentences readable by {CEFR_LEVEL} CEFR level language learners:\n"
        for i in range(len(prompt_case_single)):
            content += f"Example {i+1}:{prompt_case_single[i]}\n\n"
    content += f"Complex:{complex_sentence}\nSimple:"
    return content


DP_STARTEGY = {
    "en": {
        "63": [5, 3], "62": [5, 3, 2], "61": [5, 3, 2, 1],
        "53": [3], "52": [3, 2], "51": [3, 2, 1],
        "43": [3], "42": [3, 2], "41": [3, 2, 1]
    },  # policy generated by dp-algorithm planner offline
}
COSPUS_LANG = {
    "CEFR-SP": ["en"],
    "CEFR-SP_whole": ["en"],
    "README": ["ar", "en", "fr", "ru", "hi"]
}
if __name__ == '__main__':
    parser = argparse.ArgumentParser(description='inference param')
    parser.add_argument('--infer_bs', type=int, default=5)
    parser.add_argument('--case_num', type=int, default=3)
    parser.add_argument("--model_name", type=str, default="/root/models/Llama-3-8B-Instruct")
    parser.add_argument("--save_dir", type=str, default="few-shot_cefrsp_28")
    parser.add_argument("--corpus", type=str, default="CEFR-SP", choices=["CEFR-SP", "README", "CEFR-SP_whole"])
    args = parser.parse_args()

    model_name = args.model_name
    llmtype = os.path.basename(model_name)
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    sampling_params = SamplingParams(temperature=0.7, top_p=0.8, repetition_penalty=1.05, max_tokens=256)
    llm = LLM(model=model_name, tensor_parallel_size=4)

    infer_bs = args.infer_bs
    case_num = args.case_num
    corpus = args.corpus

    save_dir = f"LLMGeneration/{corpus}/{args.save_dir}"
    os.makedirs(save_dir, exist_ok=True)

    for lang in COSPUS_LANG[corpus]:
        case_dict_expert = json.load(open(f"../data/prompt_expert/{lang}_expert_case_{corpus.replace('-', '').lower()}.json"))  # loading  semantic-aware exemplar selection
        case_dict_expert = padding_case(case_dict_expert)  # padding non-case

        casedf = pd.read_csv(f"../data/{lang}/{corpus}_train.csv")  # single sentence case selected in training set
        case_dict = {i:[] for i in range(1, 7)}
        for rid, row in casedf.iterrows():
            case_dict[int(row["Rating"])].append(row["Sentence"])

        for begin_cefr in [6, 5, 4]:  # as same as Barayan et al. coling, only simpify CEFR-4, 5, 6
            df = pd.read_csv(f"../data/{lang}/{corpus}_test.csv")
            df = df[df["Rating"] == begin_cefr].reset_index(drop=True)

            for target_cefr in [1, 2, 3]:
                complex_sentence = df["Sentence"].tolist()
                strategy = DP_STARTEGY[lang][f"{begin_cefr}{target_cefr}"]  # getting strategy from DPagent
                assert strategy[-1] == target_cefr

                for sid, c in enumerate(strategy):  # sub-target, the last one == target_cefr
                    generated_list = []
                    if sid == 0: bid = begin_cefr
                    else: bid = strategy[sid-1]
                    for i, sent in enumerate(complex_sentence[::infer_bs]):
                        srclist = complex_sentence[i*infer_bs:(i+1)*infer_bs]
                        input_prompt_ = [
                            get_prompt(
                                case_dict_expert[f"{bid}{target_cefr}"][:case_num],
                                case_dict[c][:case_num],
                                src, c, CEFR_Descriptors[c])
                            for src in srclist
                        ]
                        outputs = llm.generate(input_prompt_, sampling_params)
                        for output in outputs:
                            generated_text = output.outputs[0].text
                            generated_list.append(clean_llm_generation(generated_text))
                    complex_sentence = copy.deepcopy(generated_list)  # replace, iteratively simplfy using CoT

                df[f"llm_gene_CEFR{target_cefr}"] = generated_list
            df.to_csv(f"{save_dir}/{lang}_few-shot_beginCEFR{begin_cefr}.csv", index=False, sep=',')


    